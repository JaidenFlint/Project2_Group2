{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f70c72a-7048-4e19-89fb-982e8fac801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "687b64a9-7881-4d8b-b82c-d394b7cae160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, data):\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = data\n",
    "    cls = model.fit(X_train_scaled, y_train)\n",
    "    print(f'Model: {type(cls).__name__}')\n",
    "    print(f'Train score: {cls.score(X_train_scaled, y_train)}')\n",
    "    print(f'Test Score: {cls.score(X_test_scaled, y_test)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "754d1cb6-ff87-490f-84bf-96b78c9ef23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>quarter</th>\n",
       "      <th>department</th>\n",
       "      <th>day</th>\n",
       "      <th>team</th>\n",
       "      <th>targeted_productivity</th>\n",
       "      <th>smv</th>\n",
       "      <th>wip</th>\n",
       "      <th>over_time</th>\n",
       "      <th>incentive</th>\n",
       "      <th>idle_time</th>\n",
       "      <th>idle_men</th>\n",
       "      <th>no_of_style_change</th>\n",
       "      <th>no_of_workers</th>\n",
       "      <th>actual_productivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>26.16</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>7080</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.940725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>finishing</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.886500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>11</td>\n",
       "      <td>0.80</td>\n",
       "      <td>11.41</td>\n",
       "      <td>968.0</td>\n",
       "      <td>3660</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.800570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>12</td>\n",
       "      <td>0.80</td>\n",
       "      <td>11.41</td>\n",
       "      <td>968.0</td>\n",
       "      <td>3660</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.800570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>6</td>\n",
       "      <td>0.80</td>\n",
       "      <td>25.90</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>1920</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.800382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date   quarter  department       day  team  targeted_productivity  \\\n",
       "0  1/1/2015  Quarter1      sweing  Thursday     8                   0.80   \n",
       "1  1/1/2015  Quarter1  finishing   Thursday     1                   0.75   \n",
       "2  1/1/2015  Quarter1      sweing  Thursday    11                   0.80   \n",
       "3  1/1/2015  Quarter1      sweing  Thursday    12                   0.80   \n",
       "4  1/1/2015  Quarter1      sweing  Thursday     6                   0.80   \n",
       "\n",
       "     smv     wip  over_time  incentive  idle_time  idle_men  \\\n",
       "0  26.16  1108.0       7080         98        0.0         0   \n",
       "1   3.94     NaN        960          0        0.0         0   \n",
       "2  11.41   968.0       3660         50        0.0         0   \n",
       "3  11.41   968.0       3660         50        0.0         0   \n",
       "4  25.90  1170.0       1920         50        0.0         0   \n",
       "\n",
       "   no_of_style_change  no_of_workers  actual_productivity  \n",
       "0                   0           59.0             0.940725  \n",
       "1                   0            8.0             0.886500  \n",
       "2                   0           30.5             0.800570  \n",
       "3                   0           30.5             0.800570  \n",
       "4                   0           56.0             0.800382  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = \"garments_worker_productivity.csv\"\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame\n",
    "data_df = pd.read_csv(csv_file)\n",
    "\n",
    "# Review the DataFrame\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d772755b-e46c-42d2-9880-f9d4b8f60422",
   "metadata": {},
   "source": [
    "## Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ae24318-06ab-4e47-8365-f10810b1a004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                      object\n",
       "quarter                   object\n",
       "department                object\n",
       "day                       object\n",
       "team                       int64\n",
       "targeted_productivity    float64\n",
       "smv                      float64\n",
       "wip                      float64\n",
       "over_time                  int64\n",
       "incentive                  int64\n",
       "idle_time                float64\n",
       "idle_men                   int64\n",
       "no_of_style_change         int64\n",
       "no_of_workers            float64\n",
       "actual_productivity      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data types\n",
    "data_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70274d9f-8913-4d19-95d0-8c592c1ba96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_var = \"targeted_productivity\"\n",
    "# Split the features and target data\n",
    "# y = data_df[target_var].values.reshape(-1,1)\n",
    "# X = data_df.drop(columns=target_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d27efe-ae68-431d-9e52-bf9da51b74a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with your categorical column names\n",
    "categorical_cols = ['date','quarter','department','day']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddcd74a0-9311-43c6-8169-309c0f1d80dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing datasets\n",
    "X = data.drop(target_var, axis=1)  # replace with your target column\n",
    "y = data[target_var]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "34949348-a0ba-4d23-ab94-bceb51a097c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'value_counts'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Review the distinct values from y\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_counts\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'value_counts'"
     ]
    }
   ],
   "source": [
    "# Review the distinct values from y\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f48e98-571b-4b75-a2bf-dd5deb0ddd86",
   "metadata": {},
   "source": [
    "## Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a5af3951-1cdb-4c0c-8314-759f914da2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                   0.000000\n",
       "quarter                0.000000\n",
       "department             0.000000\n",
       "day                    0.000000\n",
       "team                   0.000000\n",
       "smv                    0.000000\n",
       "wip                    0.413601\n",
       "over_time              0.000000\n",
       "incentive              0.000000\n",
       "idle_time              0.000000\n",
       "idle_men               0.000000\n",
       "no_of_style_change     0.000000\n",
       "no_of_workers          0.000000\n",
       "actual_productivity    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the percentage of null values in each column\n",
    "X_train.isna().sum()/len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c0b32c8b-f8f9-4dbd-a81f-3b3ba1928fd3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m [\u001b[43mX_train_scaled\u001b[49m, X_test_scaled, y_train, y_test]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "data = [X_train_scaled, X_test_scaled, y_train, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e2033714-4049-4ee8-a8c8-9022f1670900",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2/9/2015'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21280\\3153214573.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Instantiate a StandardScaler instance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Fit the training data to the standard scaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mX_scaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Transform the training data using the scaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mX_train_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_scaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    872\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m         \"\"\"\n\u001b[0;32m    874\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 876\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m                 skip_parameter_validation=(\n\u001b[0;32m   1471\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1472\u001b[0m                 )\n\u001b[0;32m   1473\u001b[0m             ):\n\u001b[1;32m-> 1474\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    908\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m         \"\"\"\n\u001b[0;32m    911\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"n_samples_seen_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m         X = self._validate_data(\n\u001b[0m\u001b[0;32m    913\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    629\u001b[0m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 633\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"X\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    634\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    994\u001b[0m                         )\n\u001b[0;32m    995\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 998\u001b[1;33m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    999\u001b[0m                 raise ValueError(\n\u001b[0;32m   1000\u001b[0m                     \u001b[1;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m                 ) from complex_warning\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[1;31m# Use NumPy API to support order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[1;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m   2149\u001b[0m     def __array__(\n\u001b[0;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2151\u001b[0m     ) -> np.ndarray:\n\u001b[0;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2153\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2154\u001b[0m         if (\n\u001b[0;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2156\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '2/9/2015'"
     ]
    }
   ],
   "source": [
    "# Instantiate a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the training data to the standard scaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Transform the training data using the scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "\n",
    "# Transform the testing data using the scaler\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "data = [X_train_scaled, X_test_scaled, y_train, y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3d427f-aed0-4c97-87f2-0ec38d2762eb",
   "metadata": {},
   "source": [
    "# Trying Different Models of Classification to Analyze the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e41bd329-72cf-4a50-b0c5-87a3f43c1238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, data):\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = data\n",
    "    cls = model.fit(X_train_scaled, y_train)\n",
    "    print(f'Model: {type(cls).__name__}')\n",
    "    print(f'Train score: {cls.score(X_train_scaled, y_train)}')\n",
    "    print(f'Test Score: {cls.score(X_test_scaled, y_test)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "20b289c3-cabb-4316-9c9b-f6b409ea95ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_model(SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[43mdata\u001b[49m)\n\u001b[0;32m      2\u001b[0m test_model(KNeighborsClassifier(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m), data)\n\u001b[0;32m      3\u001b[0m test_model(DecisionTreeClassifier(), data)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "test_model(SVC(kernel='linear'), data)\n",
    "test_model(KNeighborsClassifier(n_neighbors=9), data)\n",
    "test_model(DecisionTreeClassifier(), data)\n",
    "test_model(RandomForestClassifier(n_estimators=128, random_state=1), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f8045a-ed07-4af0-ad13-cfb2ee6bb028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the following values for max_depth\n",
    "\n",
    "max_depths = range(1, 10)\n",
    "models = {'train_score': [], 'test_score': [], 'max_depth': []}\n",
    "\n",
    "# Loop through each value in max_depths\n",
    "for depth in max_depths:\n",
    "    clf = RandomForestClassifier(max_depth = depth)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    train_pred = clf.predict(X_train)\n",
    "    test_pred = clf.predict(X_test)\n",
    "\n",
    "    train_score = balanced_accuracy_score(y_train, train_pred)\n",
    "    test_score = balanced_accuracy_score(y_test, test_pred)\n",
    "\n",
    "    models['train_score'].append(train_score)\n",
    "    models['test_score'].append(test_score)\n",
    "    models['max_depth'].append(depth)\n",
    "\n",
    "# Create a dataframe from the models dictionary with max_depth as the index\n",
    "models_df = pd.DataFrame(models).set_index('max_depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25b8d2d-dded-41f5-8ec3-888d8dc0333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "models_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34df145-9c03-4470-a504-eab21636f2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the depth value from the plot above\n",
    "depth = \n",
    "clf = RandomForestClassifier(max_depth=depth)\n",
    "clf.fit(X_train, y_train) \n",
    "\n",
    "train_pred = clf.predict(X_train)\n",
    "test_pred = clf.predict(X_test)\n",
    "\n",
    "print('Random Forest Classifier')\n",
    "print(f'Train score: {balanced_accuracy_score(y_train, train_pred)}')\n",
    "print(f'Test Score: {balanced_accuracy_score(y_test, test_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283c65d0-2a14-491a-bde5-24338d8c889a",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aa4a03-9d1c-4acb-bffc-29468e2048c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn Plots\n",
    "sns.set()\n",
    "plt.plot(x, y)\n",
    "plt.legend('ABCDEF', ncol=2, loc='upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d893332-dc47-4b0a-8c5c-afe68636c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "data = np.random.multivariate_normal([0, 0], [[5, 2], [2, 2]], size=2000)\n",
    "data = pd.DataFrame(data, columns=['x', 'y'])\n",
    "\n",
    "for col in 'xy':\n",
    "    plt.hist(data[col], normed=True, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4c67a7-db80-44c4-a010-61dd8e71e1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in 'xy':\n",
    "    sns.kdeplot(data[col], shade=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af8362c-d9f4-445f-b994-f6f3fb6ad152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Historgram and KDE\n",
    "sns.distplot(data['x'])\n",
    "sns.distplot(data['y']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9477e88c-bc82-4af9-bbc1-da4ae0db5fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two-dimensional visualization of the data\n",
    "sns.kdeplot(data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f280f149-5294-4a0a-b2ed-c8cd1e806a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joint distribution and the marginal distributions\n",
    "with sns.axes_style('white'):\n",
    "    sns.jointplot(\"x\", \"y\", data, kind='kde');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acceeb8-d98b-4e79-911f-a5c96bb03483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hexagonally based histogram instead\n",
    "with sns.axes_style('white'):\n",
    "    sns.jointplot(\"x\", \"y\", data, kind='hex')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2c6c08-eee8-44f7-acff-6d9ccbba6c2d",
   "metadata": {},
   "source": [
    "# stuff below is extra old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f599d16-a528-47d9-afb7-d226c127f3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model and Fit to a Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4982cf8-82d5-4e7b-8f00-f9ea4b8b621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the support vector machine classifier model with a 'linear' kernel\n",
    "svm_model = SVC(kernel='linear')\n",
    "\n",
    "# Fit the model to the training data\n",
    "svm_model.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b708a532-5215-4051-ba3a-bd2dc728f892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model by checking the model accuracy with model.score\n",
    "print('Train Accuracy: %.3f' % svm_model.score(X_train_encoded, y_train))\n",
    "print('Test Accuracy: %.3f' % svm_model.score(X_test_encoded, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883ce501-ebe5-4850-9e71-9b4447f97c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model and Fit to a KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ea6bb0-0d49-497e-9a7a-9ac07dc7a97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the KNN model with 9 neighbors\n",
    "knn_model = KNeighborsClassifier(n_neighbors=9)\n",
    "\n",
    "# Fit the model to the training data\n",
    "knn_model.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813d41d3-bea1-4f5d-af75-bb1eaa8267c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model by checking the model accuracy with model.score\n",
    "print('Train Accuracy: %.3f' % knn_model.score(X_train_encoded, y_train))\n",
    "print('Test Accuracy: %.3f' % knn_model.score(X_test_encoded, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd26ff47-07ac-4f1e-a89b-9e01bfa946f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model and Fit to a Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3efafcd-0578-4f82-b91e-1614c01787d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the decision tree classifier model\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the model to the training data\n",
    "dt_model.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75204885-a40e-466b-b0a1-6b6e3cdab0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model by checking the model accuracy with model.score\n",
    "print('Train Accuracy: %.3f' % dt_model.score(X_train_encoded, y_train))\n",
    "print('Test Accuracy: %.3f' % dt_model.score(X_test_encoded, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efad79fb-079c-4821-a3d8-9dfc26cb1d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model and Fit to a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272c73d2-926b-40ac-a670-b814748b7e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random forest classifier model\n",
    "# with n_estimators=128 and random_state=1\n",
    "rf_model = RandomForestClassifier(n_estimators=128, random_state=1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf_model.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb4266b-4b43-4dc3-9bf7-f58be4a7f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model by checking the model accuracy with model.score\n",
    "print('Train Accuracy: %.3f' % rf_model.score(X_train_encoded, y_train))\n",
    "print('Test Accuracy: %.3f' % rf_model.score(X_test_encoded, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515cbb26-615c-4eb1-a046-53cb15060da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all models' scores\n",
    "print(\"Logistic Regression Model\")\n",
    "print('Train Accuracy: %.3f' % lr_model.score(X_train_encoded, y_train))\n",
    "print('Test Accuracy: %.3f' % lr_model.score(X_test_encoded, y_test))\n",
    "print(\"----------------------------------\")\n",
    "print(\"Support Vector Machine Model\")\n",
    "print('Train Accuracy: %.3f' % svm_model.score(X_train_encoded, y_train))\n",
    "print('Test Accuracy: %.3f' % svm_model.score(X_test_encoded, y_test))\n",
    "print(\"----------------------------------\")\n",
    "print(\"K Nearest Neighbor Model\")\n",
    "print('Train Accuracy: %.3f' % knn_model.score(X_train_encoded, y_train))\n",
    "print('Test Accuracy: %.3f' % knn_model.score(X_test_encoded, y_test))\n",
    "print(\"----------------------------------\")\n",
    "print(\"Decision Tree Model\")\n",
    "print('Train Accuracy: %.3f' % dt_model.score(X_train_encoded, y_train))\n",
    "print('Test Accuracy: %.3f' % dt_model.score(X_test_encoded, y_test))\n",
    "print(\"----------------------------------\")\n",
    "print(\"Random Forrest Model\")\n",
    "print('Train Accuracy: %.3f' % rf_model.score(X_train_encoded, y_train))\n",
    "print('Test Accuracy: %.3f' % rf_model.score(X_test_encoded, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
